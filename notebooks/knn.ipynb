{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis con KNN\n",
    "## Clasificador en C++ ðŸ’ªðŸ’ª\n",
    "Vamos a probar a nuestro bichito\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir los path al ejecutable de python 3.6 y sus librerÃ­as,\n",
    "de acuerdo al virtual env que estÃ©n corriendo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory â€˜buildâ€™: File exists\n",
      "-- The C compiler identification is GNU 8.3.0\n",
      "-- The CXX compiler identification is GNU 8.3.0\n",
      "-- Check for working C compiler: /usr/bin/cc\n",
      "-- Check for working C compiler: /usr/bin/cc -- works\n",
      "-- Detecting C compiler ABI info\n",
      "-- Detecting C compiler ABI info - done\n",
      "-- Detecting C compile features\n",
      "-- Detecting C compile features - done\n",
      "-- Check for working CXX compiler: /usr/bin/c++\n",
      "-- Check for working CXX compiler: /usr/bin/c++ -- works\n",
      "-- Detecting CXX compiler ABI info\n",
      "-- Detecting CXX compiler ABI info - done\n",
      "-- Detecting CXX compile features\n",
      "-- Detecting CXX compile features - done\n",
      "Release mode\n",
      "-- Found PythonInterp: /home/tdelgado/anaconda3/bin/python (found version \"3.7.3\") \n",
      "-- Found PythonLibs: /home/tdelgado/anaconda3/lib/libpython3.7m.so\n",
      "-- pybind11 v2.3.dev0\n",
      "-- Performing Test HAS_FLTO\n",
      "-- Performing Test HAS_FLTO - Success\n",
      "-- LTO enabled\n",
      "CMAKE_INSTALL_PREFIX=/home/tdelgado/Desktop/TP2 Metodos/Tp2Metodos\n",
      "-- Configuring done\n",
      "-- Generating done\n",
      "-- Build files have been written to: /home/tdelgado/Desktop/TP2 Metodos/Tp2Metodos/build\n",
      "\u001b[35m\u001b[1mScanning dependencies of target tp2\u001b[0m\n",
      "[  8%] \u001b[32mBuilding CXX object CMakeFiles/tp2.dir/src/main.cpp.o\u001b[0m\n",
      "[ 16%] \u001b[32mBuilding CXX object CMakeFiles/tp2.dir/src/knn.cpp.o\u001b[0m\n",
      "[ 25%] \u001b[32mBuilding CXX object CMakeFiles/tp2.dir/src/wdknn.cpp.o\u001b[0m\n",
      "[ 33%] \u001b[32mBuilding CXX object CMakeFiles/tp2.dir/src/pca.cpp.o\u001b[0m\n",
      "[ 41%] \u001b[32mBuilding CXX object CMakeFiles/tp2.dir/src/eigen.cpp.o\u001b[0m\n",
      "[ 50%] \u001b[32m\u001b[1mLinking CXX executable tp2\u001b[0m\n",
      "[ 50%] Built target tp2\n",
      "\u001b[35m\u001b[1mScanning dependencies of target sentiment\u001b[0m\n",
      "[ 58%] \u001b[32mBuilding CXX object CMakeFiles/sentiment.dir/src/sentiment.cpp.o\u001b[0m\n",
      "[ 66%] \u001b[32mBuilding CXX object CMakeFiles/sentiment.dir/src/knn.cpp.o\u001b[0m\n",
      "[ 75%] \u001b[32mBuilding CXX object CMakeFiles/sentiment.dir/src/wdknn.cpp.o\u001b[0m\n",
      "[ 83%] \u001b[32mBuilding CXX object CMakeFiles/sentiment.dir/src/pca.cpp.o\u001b[0m\n",
      "[ 91%] \u001b[32mBuilding CXX object CMakeFiles/sentiment.dir/src/eigen.cpp.o\u001b[0m\n",
      "[100%] \u001b[32m\u001b[1mLinking CXX shared module sentiment.cpython-37m-x86_64-linux-gnu.so\u001b[0m\n",
      "[100%] Built target sentiment\n",
      "\u001b[36mInstall the project...\u001b[0m\n",
      "-- Install configuration: \"Release\"\n",
      "-- Installing: /home/tdelgado/Desktop/TP2 Metodos/Tp2Metodos/notebooks/sentiment.cpython-37m-x86_64-linux-gnu.so\n"
     ]
    }
   ],
   "source": [
    "!cd .. && git submodule init\n",
    "!cd .. && git submodule update\n",
    "!cd .. && mkdir build\n",
    "!cd ../build/ && rm -rf *\n",
    "!cd ../build && cmake \\\n",
    "  -DPYTHON_EXECUTABLE=\"$(which python)\" \\\n",
    "  -DCMAKE_BUILD_TYPE=Release ..\n",
    "!cd ../build && make install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tdelgado/Desktop/TP2 Metodos/Tp2Metodos/notebooks\n",
      "Python 3.7.3\n"
     ]
    }
   ],
   "source": [
    "# Verifico la correcta instalaciÃ³n. Si no falla el import estÃ¡ OK\n",
    "!pwd\n",
    "!python --version\n",
    "import sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "USAR_IMDB_LARGE = True\n",
    "DATA_SIZE = {}\n",
    "DATA_SIZE[\"test\"] = 200\n",
    "DATA_SIZE[\"train\"] = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              label\n",
       "count  50000.000000\n",
       "mean       0.500000\n",
       "std        0.500005\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        0.500000\n",
       "75%        1.000000\n",
       "max        1.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "if not USAR_IMDB_LARGE:\n",
    "    df = pd.read_csv(\"../data/imdb_small.csv\", index_col=0) \n",
    "    df = df[['review','label']]\n",
    "    df['label'] = (df['label'] == 'pos').astype('int')\n",
    "else:\n",
    "    fdf = open(\"../data/df_aclImdb.pkl\",\"rb\")\n",
    "    df = pickle.load(fdf)\n",
    "    fdf.close()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"type\"] = [\"train\"] * len(df[\"label\"].tolist()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data_set_grande.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de instancias de entrenamiento = 5000\n",
      "Cantidad de instancias de test = 200\n",
      "Class balance : 0.5074 pos 0.4926 neg\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array(df['review'].tolist())\n",
    "y = np.array(df['label'].tolist())\n",
    "orden = np.arange(X.shape[0])\n",
    "np.random.shuffle(orden)\n",
    "X = X[orden]\n",
    "y = y[orden]\n",
    "\n",
    "\n",
    "X_train = X[:DATA_SIZE[\"train\"]]\n",
    "y_train = y[:DATA_SIZE[\"train\"]]\n",
    "X_test = X[DATA_SIZE[\"train\"]:DATA_SIZE[\"train\"]+DATA_SIZE[\"test\"]]\n",
    "y_test = y[DATA_SIZE[\"train\"]:DATA_SIZE[\"train\"]+DATA_SIZE[\"test\"]]\n",
    "\n",
    "print(\"Cantidad de instancias de entrenamiento = {}\".format(len(X_train)))\n",
    "print(\"Cantidad de instancias de test = {}\".format(len(X_test)))\n",
    "\n",
    "print(\"Class balance : {} pos {} neg\".format(\n",
    "    y_train.sum() / y_train.shape[0], \n",
    "    (y_train.shape[0] - y_train.sum()) / y_train.shape[0]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords_nuestras = stopwords.words('english')\n",
    "stopwords_nuestras.append(\"br\")\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range = (1,3), binary = True, strip_accents = 'unicode', stop_words = stopwords_nuestras, use_idf = True, smooth_idf = True, min_df = 0.001, max_features = 5000)\n",
    "\n",
    "vectorizer.fit(X_train)\n",
    "\n",
    "X_train = vectorizer.transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ALFA = 300\n",
    "print(X_train.shape)\n",
    "pca_transformer = sentiment.PCA(ALFA)\n",
    "pca_transformer.fit(X_train.todense())\n",
    "X_train = pca_transformer.transform(X_train, ALFA)\n",
    "X_test = pca_transformer.transform(X_test, ALFA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#idea: para cada componente principal mido covarianza con el label y miro los valores\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_train_norm = y_train - y_train.mean()\n",
    "\n",
    "ystd = np.std(y_train)\n",
    "print(X_train.shape)\n",
    "\n",
    "covarianzas = np.zeros(ALFA)\n",
    "correlaciones = np.zeros(ALFA)\n",
    "for i in range(ALFA):\n",
    "    covarianzas[i] = ((X_train[:,i]-X_train[:,i].mean())*y_train_norm).sum()\n",
    "    correlaciones[i] = covarianzas[i]/(np.std(X_train[:,i])*ystd)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.arange(ALFA),correlaciones,marker = \"o\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 100\n",
    "\n",
    "clf = sentiment.KNNClassifier(K)\n",
    "\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "NORMA_PESADA = False\n",
    "\n",
    "if not NORMA_PESADA:\n",
    "    y_pred = clf.predict(X_test)\n",
    "else:\n",
    "    y_pred = clf.predict(X_test,covarianzas)\n",
    "    \n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
